{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_5oRe0SXilM"
   },
   "source": [
    "# Data Science Fundamentals 5\n",
    "\n",
    "Basic introduction on how to perform typical machine learning tasks with Python.\n",
    "\n",
    "Prepared by Mykhailo Vladymyrov & Aris Marcolongo,\n",
    "Science IT Support, University Of Bern, 2020\n",
    "\n",
    "This work is licensed under <a href=\"https://creativecommons.org/share-your-work/public-domain/cc0/\">CC0</a>.\n",
    "\n",
    "# Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9SxiIczg1s1k"
   },
   "source": [
    "# What is Machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xsd1MyT9eIdW"
   },
   "source": [
    "Unlike classical algorithms, created by human to analyze some data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtoqE5XO3L1j"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/alg_1.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu4Uq4k_ePoo"
   },
   "source": [
    "in machine learning the data itself is used for to define the algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2xIgm223vfa"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/alg_2.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvAyI1uzfBUT"
   },
   "source": [
    "Machine learning - learnign from data:\n",
    "* performance on a task **T**\n",
    "* improves according to measure **P**\n",
    "* with experience **E**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9YsgnbD32dk"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/alg_3.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "to8vOJeC1xjE"
   },
   "source": [
    "\n",
    "The boundary is a bit fuzzy.\n",
    "In fact when we create algorithms, the problem in hand, namely the data  related to the problem, drives us to choose one or another algorithm. And we then tune it, to perform well on a task in hand. ML formalized this procedure, allowing us to automate (part) of this process.\n",
    "\n",
    "In this 2-day course you will get acquainted with the basics of ML, where the approach to handling the data (the algorithm) is defined, or as we say \"learned\" from data in hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70_dMCX340Rm"
   },
   "source": [
    "## Classification vs regression.\n",
    "\n",
    "The two main tasks handled by (supervised) ML is regression and classification.\n",
    "In regression we aim at modeling the relationship between the system's response (dependent variable) and one or more explanatory variables (independent variables).\n",
    "\n",
    "Examples of regression would be predicting the temperature for each day of the year, or expenses of the household as a function of the number of children and adults.\n",
    "\n",
    "In classification the aim is to identify what class does a data-point belong to. For example, the species or the iris plant based on the size of its petals, or whether an email is spam or not based on its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBXGs0xRERuv"
   },
   "source": [
    "## Performance measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lx37P09Vkepw"
   },
   "source": [
    "1. Regression:\n",
    "* Mean Square Error (MSE): $mse=\\frac{1}{n}\\sum_i(y_i - \\hat y(\\bar x_i))^2$\n",
    "* Mean Absolute Error (MAE): $mae=\\frac{1}{n}\\sum_i|y_i - \\hat y(\\bar x_i)|$\n",
    "* Median Absolute Deviation (MAD): $mad=median(|y_i - \\hat y(\\bar x_i)|)$\n",
    "* Fraction of the explained variance: $R^2=1-\\frac{\\sum_i(y_i - \\hat y(\\bar x_i))^2}{\\sum_i(y_i - \\bar y_i)^2}$, where $\\bar y=\\frac{1}{n}\\sum_i y_i$\n",
    "\n",
    "2. Classification:\n",
    "* Confusion matrix \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSH3blOw36jz"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/confusion_mtr.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MK2gGVJyfdUJ"
   },
   "source": [
    "* Accuracy $=\\frac{TP+TN}{TP+FP+FN+TN}$\n",
    "* Precision $=\\frac{TP}{TP+FP}$\n",
    "* Recall $=\\frac{TP}{TP+FN}$\n",
    "* F1 $=2\\frac{Precision \\cdot Recall}{Precision+Recall} = \\frac{2 TP}{2 TP + FP+FN}$\n",
    "* Threat score (TS), or Intersection over Union (IoU): IoU=$\\frac{TP}{TP+FN+FP}$\n",
    "\n",
    "During model optimization the used measure in most cases must be differentiable. To this end usually some measure of similarities of distributions are employed (e.g. cross-entropy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AD6zwuTHiYKA"
   },
   "source": [
    "## Actual aim: Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNsD3FQS4JP7"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/Bias_variance_1.png\" width=\"35%\"/>\n",
    "\n",
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/Bias_variance_2.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoONru7ji3QD"
   },
   "source": [
    "To measure model performance in an unbiassed way, we need to use different data than the data that the model was trained on. For this we use the 'train-test' split: e.g. 20% of all available dataset is reserved for model performance test, and the remaining 80% is used for actual model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVSRftm8X1m1"
   },
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVJn0ilgOS8F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scikit-learn (formerly scikits.learn and also known as sklearn) is a free \n",
    "# software machine learning library for the Python programming language. \n",
    "# It features various classification, regression and clustering algorithms, \n",
    "# and is designed to interoperate with the Python numerical and scientific \n",
    "# libraries NumPy and SciPy. (from wiki)\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# common visualization module\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# numeric library\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "from time import time as timer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Y7aMevU3Ug8"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    path = os.path.abspath('.')+'/colab_material.tgz'\n",
    "    tf.keras.utils.get_file(path, 'https://github.com/neworldemancer/DSF5/raw/master/colab_material.tgz')\n",
    "    !tar -xvzf colab_material.tgz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pclZR6uFklf_"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_wxOrdWko8W"
   },
   "source": [
    "In this course we will use several synthetic and real-world datasets to illustrate the behavior of the models and exercise our skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UQgU5I-lEll"
   },
   "source": [
    "## 1. Synthetic linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGfWOWRjlWPa"
   },
   "outputs": [],
   "source": [
    "def get_linear(n_d=1, n_points=10, w=None, b=None, sigma=5):\n",
    "  x = np.random.uniform(0, 10, size=(n_points, n_d))\n",
    "  \n",
    "  w = w or np.random.uniform(0.1, 10, n_d)\n",
    "  b = b or np.random.uniform(-10, 10)\n",
    "  y = np.dot(x, w) + b + np.random.normal(0, sigma, size=n_points)\n",
    "\n",
    "  print('true w =', w, ';  b =', b)\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RLYxGy_nBZG"
   },
   "outputs": [],
   "source": [
    "x, y = get_linear(n_d=1, sigma=0)\n",
    "plt.plot(x[:, 0], y, '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10ODDOp4nX4S"
   },
   "outputs": [],
   "source": [
    "n_d = 2\n",
    "x, y = get_linear(n_d=n_d, n_points=100)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], y, marker='x', color='b',s=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJ5rjq7fIe8Q"
   },
   "source": [
    "## 2. House prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-45usskInlD"
   },
   "source": [
    "Subset of the Ames Houses dataset: http://jse.amstat.org/v19n3/decock.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVv2ID96IyN0"
   },
   "outputs": [],
   "source": [
    "def house_prices_dataset(return_df=False, price_max=400000, area_max=40000):\n",
    "  path = 'data/AmesHousing.csv'\n",
    "\n",
    "  df = pd.read_csv(path, na_values=('NaN', ''), keep_default_na=False)\n",
    "  \n",
    "  rename_dict = {k:k.replace(' ', '').replace('/', '') for k in df.keys()}\n",
    "  df.rename(columns=rename_dict, inplace=True)\n",
    "  \n",
    "  useful_fields = ['LotArea',\n",
    "                  'Utilities', 'OverallQual', 'OverallCond',\n",
    "                  'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond',\n",
    "                  'HeatingQC', 'CentralAir', 'Electrical',\n",
    "                  '1stFlrSF', '2ndFlrSF','GrLivArea',\n",
    "                  'FullBath', 'HalfBath',\n",
    "                  'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
    "                  'Functional','PoolArea',\n",
    "                  'YrSold', 'MoSold'\n",
    "                  ]\n",
    "  target_field = 'SalePrice'\n",
    "\n",
    "  df.dropna(axis=0, subset=useful_fields+[target_field], inplace=True)\n",
    "\n",
    "  cleanup_nums = {'Street':      {'Grvl': 0, 'Pave': 1},\n",
    "                  'LotFrontage': {'NA':0},\n",
    "                  'Alley':       {'NA':0, 'Grvl': 1, 'Pave': 2},\n",
    "                  'LotShape':    {'IR3':0, 'IR2': 1, 'IR1': 2, 'Reg':3},\n",
    "                  'Utilities':   {'ELO':0, 'NoSeWa': 1, 'NoSewr': 2, 'AllPub': 3},\n",
    "                  'LandSlope':   {'Sev':0, 'Mod': 1, 'Gtl': 3},\n",
    "                  'ExterQual':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'ExterCond':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'BsmtQual':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtCond':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtExposure':{'NA':0, 'No':1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "                  'BsmtFinType1':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'BsmtFinType2':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'HeatingQC':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'CentralAir':  {'N':0, 'Y': 1},\n",
    "                  'Electrical':  {'':0, 'NA':0, 'Mix':1, 'FuseP':2, 'FuseF': 3, 'FuseA': 4, 'SBrkr': 5},\n",
    "                  'KitchenQual': {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Functional':  {'Sal':0, 'Sev':1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2':5, 'Min1':6, 'Typ':7},\n",
    "                  'FireplaceQu': {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'PoolQC':      {'NA':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Fence':       {'NA':0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv':4},\n",
    "                  }\n",
    "\n",
    "  df_X = df[useful_fields].copy()                              \n",
    "  df_X.replace(cleanup_nums, inplace=True)  # convert continous categorial variables to numerical\n",
    "  df_Y = df[target_field].copy()\n",
    "\n",
    "  x = df_X.to_numpy().astype(np.float32)\n",
    "  y = df_Y.to_numpy().astype(np.float32)\n",
    "\n",
    "  if price_max>0:\n",
    "    idxs = y<price_max\n",
    "    x = x[idxs]\n",
    "    y = y[idxs]\n",
    "\n",
    "  if area_max>0:\n",
    "    idxs = x[:,0]<area_max\n",
    "    x = x[idxs]\n",
    "    y = y[idxs]\n",
    "\n",
    "  return (x, y, df) if return_df else (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqWU0eHts1RM"
   },
   "outputs": [],
   "source": [
    "x, y, df = house_prices_dataset(return_df=True)\n",
    "print(x.shape, y.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91nj7znzMEpA"
   },
   "outputs": [],
   "source": [
    "plt.plot(x[:, 0], y, '.')\n",
    "plt.xlabel('area, sq.ft')\n",
    "plt.ylabel('price, $');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7CNxkPdNB4L"
   },
   "source": [
    "## 3. Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8wXhleONKgZ"
   },
   "outputs": [],
   "source": [
    "x, y = make_blobs(n_samples=1000, centers=[[0,0], [5,5], [10, 0]])\n",
    "colors = \"bry\"\n",
    "for i, color in enumerate(colors):\n",
    "    idx = y == i\n",
    "    plt.scatter(x[idx, 0], x[idx, 1], c=color, edgecolor='gray', s=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8S1jwU4cXQX4"
   },
   "source": [
    "## 4. MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2u82UQ5XQX4"
   },
   "source": [
    "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. The digits have been size-normalized and centered in a fixed-size image.\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting (taken from http://yann.lecun.com/exdb/mnist/). Each example is a 28x28 grayscale image and the dataset can be readily downloaded from Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaNaGGOkXQX5"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlUY5gl8XQX7"
   },
   "source": [
    "Let's check few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtYtGEDdXQX8"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, ax = plt.subplots(n, n, figsize=(2*n, 2*n))\n",
    "ax = [ax_xy for ax_y in ax for ax_xy in ax_y]\n",
    "for axi, im_idx in zip(ax, np.random.choice(len(train_images), n**2)):\n",
    "  im = train_images[im_idx]\n",
    "  im_class = train_labels[im_idx]\n",
    "  axi.imshow(im, cmap='gray')\n",
    "  axi.text(1, 4, f'{im_class}', color='r', size=16)\n",
    "plt.tight_layout(0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITfbaOgfYNsq"
   },
   "source": [
    "## 5. Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgzzOS7YYTru"
   },
   "source": [
    "`Fashion-MNIST` is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. (from https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcV2gzmuYljJ"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPw6-GoPbT6U"
   },
   "source": [
    "Let's check few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHFd0sFHY4Li"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, ax = plt.subplots(n, n, figsize=(2*n, 2*n))\n",
    "ax = [ax_xy for ax_y in ax for ax_xy in ax_y]\n",
    "for axi, im_idx in zip(ax, np.random.choice(len(train_images), n**2)):\n",
    "  im = train_images[im_idx]\n",
    "  im_class = train_labels[im_idx]\n",
    "  axi.imshow(im, cmap='gray')\n",
    "  axi.text(1, 4, f'{im_class}', color='r', size=16)\n",
    "plt.tight_layout(0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHEA0tCLagoV"
   },
   "source": [
    "Each of the training and test examples is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHRXds9U9134"
   },
   "source": [
    "# `scikit-learn` interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2toQKrAzH_U"
   },
   "source": [
    "In this course we will primarily use the `scikit-learn` module.\n",
    "You can find extensive documentation with examples in the [user guide](https://scikit-learn.org/stable/user_guide.html)\n",
    "\n",
    "The module contains A LOT of different machine learning methods, and here we will cover only few of them. What is great about `scikit-learn` is that it has a uniform and consistent interface. \n",
    "\n",
    "All the different ML approaches are implemented as classes with a set of same main methods:\n",
    "\n",
    "1. `fitter = ...`: Create object.\n",
    "2. `fitter.fit(x, y[, sample_weight])`: Fit model.\n",
    "3. `y_pred = fitter.predict(X)`: Predict using the linear model.\n",
    "4. `s = score(x, y[, sample_weight])`: Return an appropriate measure of model performance.\n",
    "\n",
    "This allows one to easily replace one approach with another and find the best one for the problem at hand, by simply using another regression/classification object, while the rest of the code can remain the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to know that generally in scikit-learn the input data is represented as a design matrix $X$ of dimensions `n_samples x n_features` , whereas the supervised labels/values are stored in a matrix $Y$ of dimensions `n_samples x n_target` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4qgOdz7Yyeb"
   },
   "source": [
    "# 1.Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hh6lII-Hz8u-"
   },
   "source": [
    "In many cases the scalar value of interest - dependent variable - is (or can be approximated as) linear combination of the independent variables. \n",
    "\n",
    "In linear regression the estimator is searched in the form: $$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n",
    "\n",
    "The parameters $w = (w_1,..., w_p)$ and $w_0$ are designated as `coef_` and `intercept_` in `sklearn`.\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vlf6_berQ1vq"
   },
   "source": [
    "## 1. Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zatxRr8bOuTs"
   },
   "source": [
    "LinearRegression fits a linear model with coefficients $w = (w_1,..., w_p)$ and $w_0$ to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation. Mathematically it solves a problem of the form: $$\\min_{w} || X w - y||_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqh7XwGkNg6r"
   },
   "outputs": [],
   "source": [
    "x, y = get_linear(n_d=1, sigma=3, n_points=30)  # p==1, 1D input\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFawJfQJOKX3"
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diHNLTNMOek5"
   },
   "outputs": [],
   "source": [
    "w, w0 = reg.coef_, reg.intercept_\n",
    "print(w, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hyeHY3bxPYSF"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, marker='*')\n",
    "x_f = np.linspace(x.min(), x.max(), 10)\n",
    "y_f = w0 + w[0] * x_f\n",
    "plt.plot(x_f, y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNX-5gYOIi40"
   },
   "outputs": [],
   "source": [
    "# mse\n",
    "np.std(y - reg.predict(x))  # or use metrics.mean_squared_error(..., squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ID0Hdzx0NvxF"
   },
   "outputs": [],
   "source": [
    "# R2\n",
    "reg.score(x, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rg2_DZCHgJE"
   },
   "source": [
    "Let's try 2D input. \n",
    "Additionally, here we will split the whole dataset into training and test subsets using the `train_test_split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oK5MILosSI7d"
   },
   "outputs": [],
   "source": [
    "n_d = 2\n",
    "x, y = get_linear(n_d=n_d, n_points=100, sigma=5)\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_train[:,0], x_train[:,1], y_train, marker='x', color='b',s=40)\n",
    "ax.scatter(x_test[:,0], x_test[:,1], y_test, marker='+', color='r',s=80)\n",
    "\n",
    "xx0 = np.linspace(x[:,0].min(), x[:,0].max(), 10)\n",
    "xx1 = np.linspace(x[:,1].min(), x[:,1].max(), 10)\n",
    "xx0, xx1 = [a.flatten() for a in np.meshgrid(xx0, xx1)]\n",
    "xx = np.stack((xx0, xx1), axis=-1)\n",
    "yy = reg.predict(xx)\n",
    "ax.plot_trisurf(xx0, xx1, yy, alpha=0.5, color='g');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kW5GiLlhS3Y8"
   },
   "outputs": [],
   "source": [
    "# mse\n",
    "print('train mse =', np.std(y_train - reg.predict(x_train)))\n",
    "print('test mse =', np.std(y_test - reg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_Fb1zb5S3ZG"
   },
   "outputs": [],
   "source": [
    "# R2\n",
    "print('train R2 =', reg.score(x_train, y_train))\n",
    "print('test R2 =', reg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zI6s2Amob48j"
   },
   "source": [
    "## EXERCISE 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zRi8SPiMb9FM"
   },
   "source": [
    "Use linear regression to fit house prices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vaQVHyvPcHW2"
   },
   "outputs": [],
   "source": [
    "x, y = house_prices_dataset()\n",
    "\n",
    "# 1. make train/test split\n",
    "\n",
    "# 2. fit the model\n",
    "\n",
    "# 3. evaluate MSE, MAE, and R2 on train and test datasets\n",
    "\n",
    "# 4. plot y vs predicted y for test and train parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZX9MQlORLfY"
   },
   "source": [
    "## 2. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRUwQD5UR0Vf"
   },
   "source": [
    "Logistic regression, despite its name, is a linear model for classification rather than regression. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function.\n",
    "\n",
    "In logistic regression the probability $p$ of a point belonging to a class is modeled as: $$\\frac{p}{1-p} = e^{w_0 + w_1 x_1 + ... + w_p x_p}$$\n",
    "\n",
    "The binary class $\\ell_2$ penalized logistic regression minimizes the following cost function:\n",
    "$$\\min_{w, c}  \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1) + \\lambda \\frac{1}{2}w^T w$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bJHWawkq0ev"
   },
   "outputs": [],
   "source": [
    "# make 3-class dataset for classification\n",
    "centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
    "x, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
    "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
    "x = np.dot(x, transformation)\n",
    "\n",
    "for multi_class in ('multinomial', 'ovr'):\n",
    "    clf = linear_model.LogisticRegression(solver='sag', max_iter=100,\n",
    "                             multi_class=multi_class)\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    # print the training scores\n",
    "    print(\"training accuracy : %.3f (%s)\" % (clf.score(x, y), multi_class))\n",
    "\n",
    "    # create a mesh to plot in\n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    z = z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.contourf(xx, yy, z, cmap=plt.cm.Paired)\n",
    "    plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Plot also the training points\n",
    "    colors = \"bry\"\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(x[idx, 0], x[idx, 1], c=color, cmap=plt.cm.Paired, \n",
    "                    edgecolor='gray', s=30)\n",
    "\n",
    "    # Plot the three one-against-all classifiers\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    coef = clf.coef_\n",
    "    intercept = clf.intercept_\n",
    "\n",
    "    def plot_hyperplane(c, color):\n",
    "        def line(x0):\n",
    "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
    "        plt.plot([xmin, xmax], [line(xmin), line(xmax)],\n",
    "                 ls=\"--\", color=color)\n",
    "\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        plot_hyperplane(i, color)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQ69XKdbZcA3"
   },
   "source": [
    "## EXERCISE 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__9jcqXzZaQp"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "304Ul40adUT2"
   },
   "source": [
    "We will reshape 2-d images to 1-d arrays for use in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtD8C8_4a7dP"
   },
   "outputs": [],
   "source": [
    "n_train = len(train_labels)\n",
    "x_train = train_images.reshape((n_train, -1))\n",
    "y_train = train_labels\n",
    "\n",
    "n_test = len(test_labels)\n",
    "x_test = test_images.reshape((n_test, -1))\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJj7ofWD_Wp2"
   },
   "source": [
    "Now use a multinomial logistic regression classifier, and measure the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeIKcMeV_rmk"
   },
   "outputs": [],
   "source": [
    "# 1. Create classifier\n",
    "\n",
    "# 2. fit the model\n",
    "\n",
    "# 3. evaluate accuracy on train and test datasets"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9SxiIczg1s1k",
    "pclZR6uFklf_",
    "8UQgU5I-lEll",
    "RHRXds9U9134",
    "K4qgOdz7Yyeb",
    "Vlf6_berQ1vq",
    "zI6s2Amob48j",
    "zZX9MQlORLfY",
    "AQ69XKdbZcA3"
   ],
   "name": "Course_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
